{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS18B1059.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0/cDyDbjukp1xHtj+W59s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subraja1810/BERT/blob/Master/CS18B1059!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8K7FyzzyJPJ",
        "outputId": "2ef2eadf-d9a1-4219-bf7b-aad513672e2c"
      },
      "source": [
        "!pip install bert-for-tf2\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0lDXCuLySoB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vhDS896ySph",
        "outputId": "e5d231cd-9400-4823-a08f-4b4bad070a22"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install praw"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.6/dist-packages (7.1.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.6/dist-packages (from praw) (0.57.0)\n",
            "Requirement already satisfied: update-checker>=0.17 in /usr/local/lib/python3.6/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: prawcore<2.0,>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from praw) (1.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.17->praw) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3U8jAqhyStT"
      },
      "source": [
        "from transformers import TFAutoModelForTokenClassification, AutoTokenizer \n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "import praw \n",
        "#import pandas as pd "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJNmXP8kySu4",
        "outputId": "fb8dd45e-4e88-4165-e0b1-bc3570ccdeec"
      },
      "source": [
        "model = TFAutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\") \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwIZTPxlySyn"
      },
      "source": [
        "label_list = [\n",
        "    \"O\",       # Outside of a named entity\n",
        "    \"B-MISC\",  # Beginning of a miscellaneous entity immediately after another miscellaneous entity\n",
        "    \"I-MISC\",  # Miscellaneous entity\n",
        "    \"B-PER\",   # Beginning of a person's name immediately after another person's name\n",
        "    \"I-PER\",   # Person's name\n",
        "    \"B-ORG\",   # Beginning of an organisation immediately after another organisation\n",
        "    \"I-ORG\",   # Organisation\n",
        "    \"B-LOC\",   # Beginning of a location immediately after another location\n",
        "    \"I-LOC\"    # Location\n",
        "]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE-XEwRcyS52"
      },
      "source": [
        "reddit = praw.Reddit(client_id='3PQwAJT-jv_t2g', \n",
        "                     client_secret='Lj2yqyiO-r5RO-K-7NAM7ABx9mL4qg',\n",
        "                     user_agent='RedditBoo')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKOVXFAAyS7q"
      },
      "source": [
        "def replies_of(top_comments, comment_list):\n",
        "    if len(top_comments.replies) == 0:\n",
        "        return\n",
        "    else:\n",
        "        for num, comment in enumerate(top_comments.replies):\n",
        "            try:\n",
        "                comments_list.append(str(comment.body))\n",
        "            except:\n",
        "                continue\n",
        "            replies_of(comment, comments_list)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7A05vhiEXBU"
      },
      "source": [
        "count = 0\n",
        "final_dict = {'I-LOC': [], 'I-ORG': [], 'I-PER': [], 'B-LOC': [], 'B-ORG': [], 'B-PER': [], 'B-MISC': [], 'I-MISC': []} \n",
        "word_temp = ''\n",
        "current_tag = ''\n",
        "old_tag = ''\n",
        "print_dict = {}\n",
        "print(final_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpWi4QYSEXVJ"
      },
      "source": [
        "list_of_subreddit = ['marvelstudios']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJdAdfoNEXW1"
      },
      "source": [
        "for j in list_of_subreddit:\n",
        "    top_posts = reddit.subreddit(j).top('month', limit=1)\n",
        "    comments_list = [] #Data fetched.\n",
        "    # save subreddit comments in dataframe\n",
        "    for submission in top_posts:\n",
        "        submission_comm = reddit.submission(id=submission.id)\n",
        "        comments_list.append(str(submission.title))\n",
        "\n",
        "        for count, top_comments in enumerate(submission_comm.comments):\n",
        "            try:\n",
        "                replies_of(top_comments, comments_list)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "print(comments_list)                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ie968P3EXaQ"
      },
      "source": [
        "for sequence in comments_list:\n",
        "    if len(sequence) > 512: #BERT token limitaton.\n",
        "        continue\n",
        "    # Standard Tokenization\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
        "    inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
        "    outputs = model(inputs)[0]\n",
        "    predictions = tf.argmax(outputs, axis=2)\n",
        "    #print(predictions)\n",
        "    # Tokenized input\n",
        "    list_bert = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].numpy())]\n",
        "    for i in list_bert:\n",
        "        if i[1] in ['O']:\n",
        "            if len(current_tag) > 0:\n",
        "                without_space_word = word_temp.strip()\n",
        "                if len(without_space_word) > 1:\n",
        "                    final_dict[current_tag].append(without_space_word)\n",
        "            count = 0\n",
        "            word_temp = ''\n",
        "            current_tag = ''\n",
        "            continue\n",
        "        else:\n",
        "            current_tag = i[1]\n",
        "\n",
        "            if old_tag != current_tag and len(old_tag) > 0:\n",
        "                without_space_word = word_temp.strip()\n",
        "                if len(without_space_word) > 1:\n",
        "                    final_dict[old_tag].append(without_space_word)\n",
        "                count = 0\n",
        "                word_temp = ''\n",
        "                current_tag = ''\n",
        "\n",
        "            if i[0].startswith('##'): \n",
        "                word_temp += i[0][2:].upper()\n",
        "            elif i[1] in ['I-PER', 'I-ORG', 'I-LOC', 'B-LOC', 'B-ORG', 'B-PER', 'B-MISC', 'I-MISC']:\n",
        "                word_temp += \" \" + i[0].upper()\n",
        "                current_tag = i[1]\n",
        "                count += 1\n",
        "            old_tag = current_tag"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOiK94iNeCWb"
      },
      "source": [
        "print(final_dict)\n",
        "print_dict['Location']=list(set(final_dict['I-LOC']+final_dict['B-LOC']))\n",
        "print_dict['Organisation']=list(set(final_dict['I-ORG']+final_dict['B-ORG']))\n",
        "print_dict['Person Name']=list(set(final_dict['I-PER']+final_dict['B-PER']))\n",
        "print_dict['Miscellaneous']=list(set(final_dict['I-MISC']+final_dict['B-MISC']))\n",
        "print('')\n",
        "print(print_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJJWDzwNvQGE"
      },
      "source": [
        "#sequence,tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCq84T_wcvrM"
      },
      "source": [
        "locations=final_dict['I-LOC']+final_dict['B-LOC']\n",
        "organisations=final_dict['I-ORG']+final_dict['B-ORG']\n",
        "names=final_dict['I-PER']+final_dict['B-PER']\n",
        "miscs=final_dict['I-MISC']+final_dict['B-MISC']"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl3Mxs7smE-1"
      },
      "source": [
        "from collections import Counter\n",
        "loc_count=Counter(locations)\n",
        "org_count=Counter(organisations)\n",
        "names_count=Counter(names)\n",
        "miscs_count=Counter(miscs)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWktOYlmmFH-"
      },
      "source": [
        "loc_key=loc_count.keys()\n",
        "loc_value=loc_count.values()\n",
        "org_key=org_count.keys()\n",
        "org_value=org_count.values()\n",
        "names_key=names_count.keys()\n",
        "names_value=names_count.values()\n",
        "miscs_key=miscs_count.keys()\n",
        "miscs_value=miscs_count.values()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5nkE2QLmFRQ"
      },
      "source": [
        "height=10\n",
        "width=15\n",
        "plt.figure(figsize=(width,height))\n",
        "plt.bar(loc_key,loc_value)\n",
        "plt.title('Location with respect to Time', fontsize=35)\n",
        "plt.xlabel('Location', fontsize=20)\n",
        "plt.ylabel('Occurances', fontsize=20)\n",
        "plt.xticks(rotation=90, fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4y6bpBkwU3X"
      },
      "source": [
        "height=20\n",
        "width=50\n",
        "plt.figure(figsize=(width,height))\n",
        "plt.bar(names_key,names_value)\n",
        "plt.title('Person names with respect to Time', fontsize=60)\n",
        "plt.xlabel('Person Names', fontsize=50)\n",
        "plt.ylabel('Occurances', fontsize=50)\n",
        "plt.xticks(rotation=90, fontsize=30)\n",
        "plt.yticks(fontsize=30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzTjOFpKv8N2"
      },
      "source": [
        "height=10\n",
        "width=30\n",
        "plt.figure(figsize=(width,height))\n",
        "plt.bar(miscs_key,miscs_value)\n",
        "plt.title('Miscellaneous with respect to Time', fontsize=50)\n",
        "plt.xlabel('Miscellaneous', fontsize=40)\n",
        "plt.ylabel('Occurances', fontsize=40)\n",
        "plt.xticks(rotation=90, fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTQmCZuqwUq8"
      },
      "source": [
        "height=20\n",
        "width=50\n",
        "plt.figure(figsize=(width,height))\n",
        "x=np.array(org_key)\n",
        "y=np.array(org_value)\n",
        "plt.barh(x, y)\n",
        "plt.xticks(rotation=90,fontsize=25)\n",
        "plt.yticks(fontsize=25)\n",
        "plt.title('Organisation with respect to Time', fontsize=60)\n",
        "plt.xlabel('Occurances',fontsize=40)\n",
        "plt.ylabel('Organisation',fontsize=40)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkXhp2gAB1g4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTESIfuOB1zh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9goVWSNuna"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_GJIeJ_NvaC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRAeP_NONvuM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKds5bNVNvNr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX8cfQFBNuZv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETP43-UdB1-q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkk4TQANB2Ic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2tvCCIIB2Rq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgrsJfCmFhq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceXbDf75Be23"
      },
      "source": [
        "list_of_loc = final_dict['I-LOC']\n",
        "#list_of_org = final_dict['I-ORG']\n",
        "#list_of_person = final_dict['I-PER']\n",
        "#list_of_misc = final_dict['I-MISC']\n",
        "frequency = {}\n",
        "for loc in list_of_loc:\n",
        "  frequency[loc] = frequency.get(loc, 0) +1\n",
        "  print(frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngf1-dnPZZEh",
        "outputId": "5e596935-de35-4ab1-9673-60fee67c03c6"
      },
      "source": [
        "#outputs[0][6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([-0.7641342 , -2.4077516 , -2.0843105 , -3.2465644 ,  0.10769157,\n",
              "       -2.4875414 ,  1.225174  , -1.9893391 ,  7.9986925 ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TJtjlgAoZmnm",
        "outputId": "a8c44888-47e9-4f85-b250-d7e5c00bfd5b"
      },
      "source": [
        "#label_list[8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I-LOC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vIISZiiaJ1h",
        "outputId": "ec79d0eb-6fb6-488f-8e78-de1a0e614888"
      },
      "source": [
        "#sequence,tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I am Ajay from Chennai',\n",
              " ['[CLS]', 'I', 'am', 'A', '##jay', 'from', 'Chennai', '[SEP]'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vJfTM7OaZsp",
        "outputId": "b808cb1e-7dcb-41e3-aafb-c539c08237db"
      },
      "source": [
        "#predictions.numpy()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 4, 4, 0, 8, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}